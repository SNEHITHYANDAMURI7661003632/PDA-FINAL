# -*- coding: utf-8 -*-
"""LVADSUSR107_PDA _FINAL_CLUSTER.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kanKO4-n3ZO6ciHczuxwVFYqIWekcr7m
"""

import pandas as pd
import numpy as np
df=pd.read_csv('/content/seeds.csv')
df.head()

df.isnull().sum()

df.fillna(df.mean(),inplace=True)
df.isnull().sum()

df.corr()
import seaborn as sns
sns.heatmap(df.corr(),annot=True)
df.duplicated().sum()
df.drop_duplicates()

sns.boxplot(df)

Q1 = df['Asymmetry coefficient'].quantile(0.25)
Q3 = df['Asymmetry coefficient'].quantile(0.75)
IQR = Q3 - Q1


lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

df_no_outliers = df[(df['Asymmetry coefficient'] >= lower_bound) & (df['Asymmetry coefficient'] <= upper_bound)]

print("Original DataFrame:")
print(df)
print("\nDataFrame after removing outliers:")
print(df_no_outliers)

df.duplicated().sum()
df.drop_duplicates()

import matplotlib.pyplot as plt
import seaborn as sns

plt.hist(df)

plt.title('Histogram')
plt.show()

df

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import StandardScaler,LabelEncoder
from sklearn.decomposition import PCA



features = ['Area','Perimeter','Compactness','Length of kernel','Width of kernel','Asymmetry coefficient','Length of kernel groove']
X = df[features]
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)


silhouette_scores = []
k_range = range(2, 11)

for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_scaled)
    silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))
print(silhouette_scores)


plt.plot(k_range, silhouette_scores, marker='o')
plt.xlabel('Number of Clusters')
plt.ylabel('Silhouette Score')
plt.title('Silhouette Score vs Number of Clusters')
plt.show()


sse = []
for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_scaled)
    sse.append(kmeans.inertia_)

plt.plot(k_range, sse, marker='o')
plt.xlabel('Number of Clusters')
plt.ylabel('Sum of Squared Distances (SSE)')
plt.title('Elbow Method')
plt.show()

optimal_k = 3
kmeans = KMeans(n_clusters=optimal_k, random_state=42)
kmeans.fit(X_scaled)
cluster_labels = kmeans.labels_


plt.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, cmap='viridis')
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.title('Cluster Graph')
plt.show()


centroids = kmeans.cluster_centers_
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, cmap='viridis', label='Clusters')
plt.scatter(centroids[:, 0], centroids[:, 1], marker='x', s=200, c='red', label='Centroids')
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.title('Cluster Graph with Centroids')
plt.legend()
plt.show()

k = 3

kmeans = KMeans(n_clusters=k, random_state=42)
kmeans.fit(df)

clusters = kmeans.predict(df)


plt.scatter(df['Area'], df['Perimeter'], c=clusters, cmap='viridis')
plt.xlabel('Area')
plt.ylabel('Perimeter')
plt.title('K-means Clustering')
plt.show()